# -*- coding: utf-8 -*-
"""Movie_Recommendation_System.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1V9l2ltrewNQG91BZljLFsBsoZ-jeU7zA
"""

import numpy as np
import pandas as pd

movie=pd.read_csv('/content/BollywoodMovieDetail.csv')

movie.head(1)

#gener , id , title , writer , actors , directors
movie=movie[['imdbId','title','genre','writers','actors','directors']]

movie

movie.shape

movie.isnull().sum

movie.dropna(inplace=True)

movie

!pip install movieposters

import movieposters as mp

link = mp.get_poster(id='tt4045666')
link

import urllib.request
from PIL import Image

urllib.request.urlretrieve(link,'poster.png')
img = Image.open('poster.png')
img.show()

movie.duplicated().sum()

movie.iloc[1].genre

movie['genre'].dtype

movie['actors']

movie['actors']= movie['actors'].str.replace('|', ',')
movie['genre']= movie['genre'].str.replace('|', ',')
movie['writers']= movie['writers'].str.replace('|', ',')

movie['actors'][0]

movie['actors']= movie['actors'].str.replace(' ', '')
movie['genre']= movie['genre'].str.replace(' ', '')
movie['writers']= movie['writers'].str.replace(' ', '')
movie['actors'][0]
movie['writers'][3]

movie

movie['tags']=movie['genre'] +" "+ movie['actors']+" " + movie['directors']+" "+movie['writers']

movie['tags']

new_movies=movie[['imdbId','title','tags']]

new_movies['tags']= new_movies['tags'].str.replace(',', ' ')

new_movies['tags'][0]

new_movies['title']= new_movies['title'].str.replace(',', ' ')
new_movies['title'][1]

new_movies['imdbId']= new_movies['imdbId'].str.replace(',', ' ')

new_movies['tags'][0]

new_movies['tags']=new_movies['tags'].apply(lambda x:x.lower())

new_movies.head()

new_movies

new_movies['genre']=movie['genre']

new_movies

"""convert tags (text) into vectors - text vectorization , bag of word technique
combine all tags - large text find  out 5000 find out top 5000 words which has high frequency exract them
"""

from sklearn.feature_extraction.text import CountVectorizer
cv=CountVectorizer(max_features=5000)

vectors=cv.fit_transform(new_movies['tags']).toarray()
vectors

vectors[0]

cv.get_feature_names_out

import nltk
from nltk.stem.porter import PorterStemmer
ps=PorterStemmer()

def stem(text):
  y=[]

  for i in text.split():
    y.append(ps.stem(i))

  return" ".join(y)

new_movies['tags']=new_movies['tags'].apply(stem)

stem('adventure drama musical aamirkhan gracysingh')

from sklearn.metrics.pairwise import cosine_similarity
similarity=cosine_similarity(vectors)



sorted(list(enumerate(similarity[0])),reverse=True,key=lambda x:x[1])[1:6]
#enumerate - list is now converted into touples, relation

def recommend(movie):
  movie_index=new_movies[new_movies['title']==movie].index[0]
  distances=similarity[movie_index]
  movies_list=sorted(list(enumerate(distances)),reverse=True,key=lambda x:x[1])[1:6]

  for i in movies_list:
    print( new_movies.iloc[i[0]] )

recommend('Albela')

new_movies.iloc[8].title

import pickle

pickle.dump(new_movies.to_dict(),open('movie_dict.pkl','wb'))

new_movies['title'].values

new_movies.to_dict()

pickle.dump(similarity,open('similarity.pkl','wb'))